version: '3.8'

services:
  # Development environment container
  dev-environment:
    build:
      context: .
      dockerfile: Dockerfile

    volumes:
      # Mount workspace
      - ../:/workspace:cached

      # Persist bash history
      - devcontainer-bashhistory:/home/vscode/.bash_history

      # Persist VS Code extensions
      - devcontainer-vscode-extensions:/home/vscode/.vscode-server/extensions
      - devcontainer-vscode-extensions-insiders:/home/vscode/.vscode-server-insiders/extensions

    # Overrides default command so container stays running
    command: /bin/sh -c "while sleep 1000; do :; done"

    environment:
      # Python
      PYTHONPATH: /workspace
      PYTHONUNBUFFERED: "1"

      # Development mode
      ENVIRONMENT: development
      DEBUG: "true"

      # Service URLs (for when microservices are running)
      POSTGRES_URL: postgresql://postgres:devpassword@postgres:5432/documents
      RABBITMQ_URL: amqp://admin:password@rabbitmq:5672/
      REDIS_URL: redis://redis:6379/0
      OPENSEARCH_URL: https://opensearch:9200
      MINIO_ENDPOINT: minio:9000
      OLLAMA_URL: http://ollama:11434

    networks:
      - devcontainer-network

    # Depends on infrastructure services
    depends_on:
      - postgres
      - rabbitmq
      - redis
      - opensearch
      - minio
      - ollama

  # PostgreSQL database
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    volumes:
      - postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: documents
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: devpassword
    ports:
      - "5432:5432"
    networks:
      - devcontainer-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # RabbitMQ message broker
  rabbitmq:
    image: rabbitmq:3-management-alpine
    restart: unless-stopped
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: password
    ports:
      - "5672:5672"   # AMQP
      - "15672:15672" # Management UI
    networks:
      - devcontainer-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis cache
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - devcontainer-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # OpenSearch for semantic search
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    restart: unless-stopped
    environment:
      discovery.type: single-node
      plugins.security.disabled: "true"
      OPENSEARCH_JAVA_OPTS: "-Xms512m -Xmx512m"
      DISABLE_INSTALL_DEMO_CONFIG: "true"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    ports:
      - "9200:9200"
      - "9600:9600"
    networks:
      - devcontainer-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MinIO for object storage
  minio:
    image: minio/minio:latest
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - devcontainer-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - devcontainer-network
    # Note: Pull models manually after container is running
    # docker exec -it ollama ollama pull llama3.2-vision:11b
    # docker exec -it ollama ollama pull llama3.2:3b

networks:
  devcontainer-network:
    driver: bridge

volumes:
  # Development container volumes
  devcontainer-bashhistory:
  devcontainer-vscode-extensions:
  devcontainer-vscode-extensions-insiders:

  # Infrastructure volumes
  postgres-data:
  rabbitmq-data:
  redis-data:
  opensearch-data:
  minio-data:
  ollama-data:
