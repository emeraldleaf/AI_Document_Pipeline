# Quick Setup: Advanced Search

> **‚ö†Ô∏è PROOF OF CONCEPT** - The search feature has not been fully tested. Use at your own risk and test thoroughly before production use.

Get started with keyword, semantic, and hybrid search in **under 10 minutes**.

## What You'll Get

‚úÖ **Complete Full-Text Search** - Search ALL text from EVERY page in your documents
‚úÖ **Keyword Search** - Fast PostgreSQL FTS (< 50ms searches)
‚úÖ **Semantic Search** - AI-powered concept search (pgvector)
‚úÖ **Hybrid Search** - Best of both worlds
‚úÖ **No Size Limits** - 1-page or 1000-page documents fully indexed
‚úÖ **Multi-Format** - PDFs (all pages), Word (all paragraphs), Excel (all sheets)
‚úÖ **Free** - Runs entirely on your machine
‚úÖ **Cloud-ready** - Deploy to production with 1 line change

### Full-Text Coverage

When you enable search, **100% of your document text is searchable**:

- ‚úÖ Multi-page PDFs: ALL pages extracted and indexed
- ‚úÖ Word documents: ALL paragraphs, headers, footers, tables
- ‚úÖ Excel spreadsheets: ALL sheets and cells
- ‚úÖ No truncation: Complete documents stored in database
- ‚úÖ Fast indexing: PostgreSQL automatically creates FTS vectors
- ‚úÖ Instant searches: Find text from page 1 or page 1000 equally fast

---

## Prerequisites

- Docker installed
- Ollama running
- Python 3.9+

---

## 5-Minute Setup

### Step 1: Start PostgreSQL (30 seconds)

```bash
# Start database with pgvector
docker-compose up -d

# Verify it's running
docker-compose ps
# You should see: doc_pipeline_postgres ... Up
```

### Step 2: Install Dependencies (1 minute)

```bash
pip install -r requirements.txt
```

### Step 3: Pull Embedding Model (2 minutes)

```bash
# Download embedding model for semantic search
ollama pull nomic-embed-text

# Verify
ollama list
# You should see: nomic-embed-text
```

### Step 4: Configure (30 seconds)

Create or edit `.env` file:

```bash
cat > .env << 'EOF'
# Enable search
USE_DATABASE=true
DATABASE_URL=postgresql://docuser:devpassword@localhost:5432/documents
STORE_FULL_CONTENT=true

# Embedding config
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSION=768
EOF
```

### Step 5: Test It Works (1 minute)

```bash
# Check database connection
doc-classify search-stats

# You should see statistics table (empty is OK)
```

---

## Add Your First Documents

### Option A: Process Existing Documents

```bash
# Classify documents (creates DB entries)
doc-classify classify documents/input

# Documents are now in database with FTS index
```

### Option B: Create Test Document

```bash
# Create test directory
mkdir -p documents/input

# Create test document
cat > documents/input/test_invoice.txt << 'EOF'
INVOICE #2024-001

Date: October 25, 2024
Customer: Acme Corp

Description: Consulting services
Amount: $5,000.00

Payment terms: Net 30
EOF

# Process it
doc-classify classify documents/input
```

---

## Try Searching

### Basic Search

```bash
# Hybrid search (default - uses both keyword + semantic)
doc-classify search "invoice"

# Should return your test document
```

### Different Search Modes

```bash
# Keyword search (fast, exact matches)
doc-classify search "invoice" --mode keyword

# Semantic search (concept-based, flexible)
doc-classify search "payment document" --mode semantic
# This finds invoices even though you searched "payment"!

# Hybrid search with custom weights
doc-classify search "consulting" \
  --keyword-weight 0.7 \
  --semantic-weight 0.3
```

### Advanced Features

```bash
# Filter by category
doc-classify search "2024" --category invoices

# Show more results
doc-classify search "invoice" --limit 50

# Verbose output with previews
doc-classify search "consulting" -v
```

---

## Enable Semantic Search

Semantic search requires embeddings. Generate them:

```bash
# Generate embeddings for all documents
doc-classify reindex --include-vectors

# This takes ~1 second per document on CPU
# For 100 documents: ~2 minutes
```

Now try semantic search:

```bash
# Find documents by concept
doc-classify search "how to pay" --mode semantic

# Finds invoices, payment terms, etc.
# even without exact keyword matches!
```

---

## View Statistics

```bash
doc-classify search-stats
```

Output:
```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ     Search Statistics           ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric                  ‚îÉ Value  ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Total Documents         ‚îÇ     15 ‚îÇ
‚îÇ Total Categories        ‚îÇ      3 ‚îÇ
‚îÇ Documents with FTS      ‚îÇ     15 ‚îÇ
‚îÇ Documents with Embeddings‚îÇ     15 ‚îÇ
‚îÇ FTS Coverage            ‚îÇ  100%  ‚îÇ
‚îÇ Embedding Coverage      ‚îÇ  100%  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Common Use Cases

### 1. Find All Invoices

```bash
# Keyword search
doc-classify search "invoice" --mode keyword

# Or filter by category (if classified)
doc-classify search "*" --category invoices
```

### 2. Find Documents About a Topic

```bash
# Semantic search understands concepts
doc-classify search "refund policy" --mode semantic

# Finds: "return policy", "money back guarantee", etc.
```

### 3. Find Specific Document

```bash
# Exact match
doc-classify search "INV-2024-001" --mode keyword

# Hybrid for best results
doc-classify search "invoice 2024 001"
```

### 4. Natural Language Query

```bash
# Ask questions (semantic search)
doc-classify search "how to cancel subscription" --mode semantic

# Finds relevant documents
```

---

## Python API

```python
from src.search_service import SearchService, SearchMode
from config import settings

# Initialize search
search = SearchService(
    database_url=settings.database_url,
    embedding_provider="ollama"
)

# Search
results = search.search(
    query="invoice payment",
    mode=SearchMode.HYBRID,
    limit=10
)

# Display results
for result in results:
    print(f"{result.file_name} - Score: {result.combined_score:.4f}")
    print(f"  Preview: {result.content_preview[:100]}...")
```

---

## Troubleshooting

### PostgreSQL won't start

```bash
# Check if port 5432 is in use
lsof -i :5432

# Kill conflicting process or change port
# Then restart
docker-compose down
docker-compose up -d
```

### "Connection refused" error

```bash
# Make sure PostgreSQL is running
docker-compose ps

# Check logs
docker-compose logs postgres

# Restart if needed
docker-compose restart postgres
```

### No search results

```bash
# Check if documents are indexed
doc-classify search-stats

# If 0 documents, process some
doc-classify classify documents/input

# If no embeddings, reindex
doc-classify reindex --include-vectors
```

### Embedding model not found

```bash
# Pull the model
ollama pull nomic-embed-text

# Check it's available
ollama list

# Test Ollama
curl http://localhost:11434/api/tags
```

### Slow embedding generation

```bash
# Normal: ~1 second per document on CPU

# To speed up:
# 1. Use smaller batch size
doc-classify reindex --include-vectors --batch-size 5

# 2. Or switch to OpenAI API (faster but costs money)
# Edit .env:
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your-key
```

---

## Next Steps

### 1. Process More Documents

```bash
# Process entire directory
doc-classify classify ~/Documents --recursive

# Generate embeddings
doc-classify reindex --include-vectors
```

### 2. Integrate into Your App

```python
# See examples in SEARCH_GUIDE.md
from src.search_service import SearchService
```

### 3. Deploy to Cloud

```bash
# See DEPLOYMENT_GUIDE_PARALLEL.md for complete guide
# Summary: Just change DATABASE_URL

# Production .env:
DATABASE_URL=postgresql://user:pass@your-rds.amazonaws.com/db
```

### 4. Optimize Performance

```bash
# Add indexes (already done in migration)
# Monitor with:
doc-classify search-stats

# Regular maintenance:
docker-compose exec postgres psql -U docuser -d documents \
  -c "VACUUM ANALYZE documents"
```

---

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Your Documents        ‚îÇ
‚îÇ   (PDF, DOCX, etc.)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Extractors            ‚îÇ
‚îÇ   ‚Ä¢ PDFExtractor        ‚îÇ
‚îÇ   ‚Ä¢ DOCXExtractor       ‚îÇ
‚îÇ   ‚Ä¢ Text extraction     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL DB         ‚îÇ
‚îÇ   ‚Ä¢ Full content        ‚îÇ
‚îÇ   ‚Ä¢ Metadata            ‚îÇ
‚îÇ   ‚Ä¢ FTS index (auto)    ‚îÇ
‚îÇ   ‚Ä¢ Vector embeddings   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Search Service        ‚îÇ
‚îÇ   ‚Ä¢ Keyword (FTS)       ‚îÇ
‚îÇ   ‚Ä¢ Semantic (vectors)  ‚îÇ
‚îÇ   ‚Ä¢ Hybrid (combined)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Performance Expectations

| Documents | Indexing Time | Keyword Search | Semantic Search | Hybrid Search |
|-----------|---------------|----------------|-----------------|---------------|
| 10 | 10 seconds | < 10ms | < 20ms | < 30ms |
| 100 | 2 minutes | < 20ms | < 50ms | < 70ms |
| 1,000 | 20 minutes | < 50ms | < 100ms | < 150ms |
| 10,000 | 3 hours | < 100ms | < 200ms | < 300ms |

*Indexing time includes embedding generation with Ollama (CPU)*

---

## Cost

### POC (Local)

- **Database:** $0 (Docker)
- **Embeddings:** $0 (Ollama)
- **Compute:** $0 (your machine)
- **Total:** **$0/month**

### Production (Cloud)

- **Database:** $50-100/month (RDS/Cloud SQL)
- **Embeddings:** $0-50/month (Ollama free, OpenAI ~$10-50)
- **Compute:** $20-80/month (EC2/Cloud Run)
- **Total:** **~$70-230/month**

---

## Features

### Keyword Search
- ‚úÖ Full-text indexing
- ‚úÖ Boolean operators (AND, OR, NOT)
- ‚úÖ Phrase matching
- ‚úÖ Prefix matching
- ‚úÖ Stemming (running ‚Üí run)
- ‚úÖ Relevance ranking

### Semantic Search
- ‚úÖ Concept matching
- ‚úÖ Synonym support
- ‚úÖ Natural language queries
- ‚úÖ Typo tolerance
- ‚úÖ Cross-language (same embedding space)
- ‚úÖ Similarity ranking

### Hybrid Search
- ‚úÖ Combined ranking
- ‚úÖ Configurable weights
- ‚úÖ Best recall + precision
- ‚úÖ Automatic fallback

---

## Security

### Local Development
- ‚úÖ All data stays on your machine
- ‚úÖ No external API calls (when using Ollama)
- ‚úÖ Docker network isolation

### Production
- ‚ö†Ô∏è Use strong passwords
- ‚ö†Ô∏è Enable SSL/TLS for database
- ‚ö†Ô∏è Restrict network access (VPC)
- ‚ö†Ô∏è Rotate credentials regularly
- ‚ö†Ô∏è Enable encryption at rest

---

## Support

- **Documentation:** [SEARCH_GUIDE.md](SEARCH_GUIDE.md)
- **Deployment:** [DEPLOYMENT_GUIDE_PARALLEL.md](DEPLOYMENT_GUIDE_PARALLEL.md)
- **Database Guide:** [DATABASE_GUIDE.md](DATABASE_GUIDE.md)
- **Issues:** GitHub Issues

---

## Quick Reference

### CLI Commands

```bash
# Search
doc-classify search QUERY [--mode MODE] [--category CAT] [--limit N]

# Statistics
doc-classify search-stats

# Reindex
doc-classify reindex [--include-vectors] [--category CAT]

# Database management
doc-classify db-stats
doc-classify db-search --search QUERY
doc-classify db-export --output FILE
```

### Search Modes

- `keyword` - Fast, exact matches
- `semantic` - Smart, concept-based
- `hybrid` - Best of both (default)

### Environment Variables

```bash
DATABASE_URL=postgresql://user:pass@host:port/db
USE_DATABASE=true
STORE_FULL_CONTENT=true
EMBEDDING_PROVIDER=ollama  # or openai
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSION=768
```

---

**Ready to search!** üöÄ

Run `doc-classify search "your query"` to get started.
