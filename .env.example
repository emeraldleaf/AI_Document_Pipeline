# AI Document Pipeline Configuration
# Copy this file to .env and customize for your environment

# ============================================================================
# Ollama Configuration (for classification)
# ============================================================================
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# ============================================================================
# Document Processing Paths
# ============================================================================
INPUT_FOLDER=./documents/input
OUTPUT_FOLDER=./documents/output
TEMP_FOLDER=./documents/temp

# ============================================================================
# Classification Categories (comma-separated)
# ============================================================================
CATEGORIES=invoices,contracts,reports,correspondence,research,compliance,other

# ============================================================================
# Processing Options
# ============================================================================
MAX_FILE_SIZE_MB=100
PROCESS_SUBDIRECTORIES=true
PRESERVE_ORIGINAL_STRUCTURE=false

# ============================================================================
# Logging
# ============================================================================
LOG_LEVEL=INFO

# ============================================================================
# Database Configuration (Required for Search)
# ============================================================================

# Enable database storage
USE_DATABASE=true

# Database connection URL
# POC (Local): Use PostgreSQL with Docker
DATABASE_URL=postgresql://docuser:devpassword@localhost:5432/documents

# Production: Use cloud database
# DATABASE_URL=postgresql://user:password@your-rds-endpoint.amazonaws.com:5432/documents

# Store full document content for search (recommended)
STORE_FULL_CONTENT=true

# ============================================================================
# Search Backend Configuration
# ============================================================================

# Search backend: "postgresql" or "opensearch"
# - postgresql: Good for <50K documents, simple setup
# - opensearch: Excellent for 100K-10M+ documents, enterprise features
SEARCH_BACKEND=postgresql

# OpenSearch settings (only needed if SEARCH_BACKEND=opensearch)
OPENSEARCH_HOSTS=http://localhost:9200
OPENSEARCH_INDEX=documents

# OpenSearch security (enable for production)
OPENSEARCH_USE_SSL=false
OPENSEARCH_VERIFY_CERTS=false
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=

# ============================================================================
# Embedding Configuration (for Semantic Search)
# ============================================================================

# Embedding provider: "ollama" (free, local) or "openai" (paid, cloud)
EMBEDDING_PROVIDER=ollama

# Ollama embedding configuration (POC - Free)
# Models: nomic-embed-text (768 dims) or mxbai-embed-large (1024 dims, better precision)
EMBEDDING_MODEL=mxbai-embed-large
EMBEDDING_DIMENSION=1024

# OpenAI embedding configuration (Production - Paid)
# Uncomment these to use OpenAI embeddings instead of Ollama
# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-your-openai-api-key-here
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSION=1536

# ============================================================================
# Document Splitting (Optional)
# ============================================================================
SPLIT_DOCUMENTS=none  # Options: none, pages, sections, chunks, smart
CHUNK_SIZE=2000
CHUNK_OVERLAP=200
MIN_SECTION_SIZE=100

# ============================================================================
# Quick Start Guide
# ============================================================================
#
# POC Setup (Free - runs on your machine):
# ----------------------------------------
# 1. docker-compose up -d
# 2. ollama pull mxbai-embed-large
# 3. pip install -r requirements.txt
# 4. Copy this file to .env (use settings above)
# 5. doc-classify search "test"
#
# For 500K+ Documents (OpenSearch Setup):
# ----------------------------------------
# 1. docker-compose -f docker-compose-opensearch.yml up -d
# 2. python scripts/migrate_to_opensearch.py
# 3. Set SEARCH_BACKEND=opensearch in .env
# 4. doc-classify search "test"
#
# Production Setup (Cloud):
# -------------------------
# 1. Create cloud PostgreSQL database (AWS RDS, GCP Cloud SQL, etc.)
# 2. Enable pgvector extension
# 3. Update DATABASE_URL above
# 4. (Optional) Switch EMBEDDING_PROVIDER to openai
# 5. (Optional) For scale: Deploy OpenSearch cluster
# 6. Deploy your application
#
# See SETUP_SEARCH.md for detailed setup instructions
# See OPENSEARCH_SETUP_GUIDE.md for OpenSearch integration
# See CLOUD_MIGRATION.md for production deployment guide
#
