#!/usr/bin/env python3
"""
Semantic Search Score Demonstration

This script demonstrates why longer, more descriptive queries get higher 
semantic similarity scores than shorter ones.
"""

import numpy as np
from typing import List, Dict
import json


def simulate_embedding(text: str) -> List[float]:
    """
    Simulate text embedding generation.
    
    In reality, this would use your embedding service, but for demonstration
    we'll create vectors that show the principle.
    """
    # Simulate different semantic concepts with weights
    concepts = {
        'acme': ['company', 'business', 'organization'],
        'technical': ['technology', 'engineering', 'software', 'IT'],
        'consulting': ['services', 'professional', 'advisory', 'expertise'],
        'code': ['programming', 'software', 'development'],
        'review': ['analysis', 'evaluation', 'assessment', 'quality'],
        'qa': ['quality', 'testing', 'assurance', 'verification'],
        'quality': ['excellence', 'standards', 'testing'],
        'assurance': ['guarantee', 'reliability', 'confidence']
    }
    
    # Initialize embedding vector (simplified to 10 dimensions)
    embedding = [0.0] * 10
    words = text.lower().split()
    
    # Assign weights to different dimensions based on concepts
    for word in words:
        if 'acme' in word:
            embedding[0] += 0.8  # Company dimension
        if any(tech in word for tech in ['technical', 'code', 'software']):
            embedding[1] += 0.9  # Technical dimension
            embedding[2] += 0.7  # Engineering dimension
        if any(srv in word for srv in ['consulting', 'services']):
            embedding[3] += 0.8  # Services dimension
            embedding[4] += 0.6  # Professional dimension
        if any(qa in word for qa in ['qa', 'quality', 'review', 'assurance']):
            embedding[5] += 0.9  # Quality dimension
            embedding[6] += 0.7  # Review dimension
        if 'review' in word:
            embedding[7] += 0.8  # Analysis dimension
    
    # Normalize the vector
    norm = np.linalg.norm(embedding)
    if norm > 0:
        embedding = [x / norm for x in embedding]
    
    return embedding


def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """Calculate cosine similarity between two vectors."""
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = sum(a * a for a in vec1) ** 0.5
    magnitude2 = sum(b * b for b in vec2) ** 0.5
    
    if magnitude1 == 0 or magnitude2 == 0:
        return 0.0
    
    return dot_product / (magnitude1 * magnitude2)


def demonstrate_semantic_scoring():
    """Demonstrate why longer queries get higher semantic scores."""
    
    print("üîç SEMANTIC SEARCH SCORING DEMONSTRATION")
    print("=" * 60)
    
    # Sample document content (what's stored in your database)
    documents = {
        "doc1": "ACME Technical Consulting provides comprehensive code review and quality assurance services for enterprise software development projects.",
        "doc2": "Annual report from ACME Corporation showing financial performance and market position.",
        "doc3": "ACME Manufacturing quality control processes and industrial standards compliance.",
        "doc4": "Technical documentation for ACME software products and API integration guides."
    }
    
    # Different search queries
    queries = {
        "short": "acme",
        "medium": "acme technical consulting",
        "long": "acme technical consulting code review and qa",
        "specific": "acme technical consulting code review and quality assurance services"
    }
    
    print("üìÑ SAMPLE DOCUMENTS:")
    for doc_id, content in documents.items():
        print(f"{doc_id}: {content[:80]}...")
    
    print("\nüîç SEARCH QUERIES:")
    for query_name, query_text in queries.items():
        print(f"{query_name}: '{query_text}'")
    
    print("\nüìä SEMANTIC SIMILARITY SCORES:")
    print("-" * 100)
    print(f"{'Query':<12} {'Document':<8} {'Similarity':<12} {'Explanation'}")
    print("-" * 100)
    
    # Calculate similarities
    results = {}
    
    for query_name, query_text in queries.items():
        query_embedding = simulate_embedding(query_text)
        results[query_name] = {}
        
        for doc_id, doc_content in documents.items():
            doc_embedding = simulate_embedding(doc_content)
            similarity = cosine_similarity(query_embedding, doc_embedding)
            results[query_name][doc_id] = similarity
            
            # Explanation
            explanation = ""
            if doc_id == "doc1" and "technical consulting" in query_text:
                explanation = "Perfect match - technical consulting services"
            elif doc_id == "doc1" and query_name == "short":
                explanation = "Only company name matches"
            elif doc_id == "doc2":
                explanation = "Corporate/financial content"
            elif doc_id == "doc3":
                explanation = "Manufacturing QC (different domain)"
            elif doc_id == "doc4":
                explanation = "Technical docs (partial match)"
            
            print(f"{query_name:<12} {doc_id:<8} {similarity:.3f}        {explanation}")
    
    print("\nüìà KEY INSIGHTS:")
    print("-" * 60)
    
    # Find the most relevant document (doc1 - technical consulting)
    target_doc = "doc1"
    
    print(f"For the most relevant document ({target_doc}):")
    for query_name, query_text in queries.items():
        score = results[query_name][target_doc]
        print(f"  '{query_text}' ‚Üí {score:.3f}")
    
    print(f"\nüéØ WHY LONGER QUERIES SCORE HIGHER:")
    print("1. More semantic context = richer vector representation")
    print("2. Multiple concept matches (acme + technical + consulting + qa)")
    print("3. Better intent understanding (user wants technical services)")
    print("4. Reduced ambiguity (not just any mention of 'acme')")
    
    print(f"\n‚öñÔ∏è COMPARISON:")
    short_score = results["short"][target_doc]
    long_score = results["long"][target_doc]
    improvement = ((long_score - short_score) / short_score) * 100
    
    print(f"Short query ('acme'): {short_score:.3f}")
    print(f"Long query ('acme technical...'): {long_score:.3f}")
    print(f"Improvement: {improvement:.1f}% higher relevance score")
    
    print(f"\n‚úÖ THIS IS CORRECT BEHAVIOR!")
    print("Semantic search should favor specific, contextual queries")
    print("that better express user intent and match document content.")
    
    return results


def show_vector_analysis():
    """Show how different queries create different vector patterns."""
    
    print("\nüßÆ VECTOR ANALYSIS:")
    print("=" * 60)
    
    queries = [
        "acme",
        "acme technical consulting",
        "acme technical consulting code review and qa"
    ]
    
    print("Query embeddings (simplified to 10 dimensions):")
    print("Dimensions: [company, technical, engineering, services, professional, quality, review, analysis, ...]")
    print("-" * 100)
    
    for query in queries:
        embedding = simulate_embedding(query)
        formatted_embedding = [f"{x:.2f}" for x in embedding[:8]]  # Show first 8 dimensions
        print(f"'{query}':")
        print(f"  Vector: [{', '.join(formatted_embedding)}, ...]")
        
        # Show dominant concepts
        concepts = []
        if embedding[0] > 0.1: concepts.append("company")
        if embedding[1] > 0.1: concepts.append("technical")
        if embedding[3] > 0.1: concepts.append("services")
        if embedding[5] > 0.1: concepts.append("quality")
        
        print(f"  Concepts: {', '.join(concepts) if concepts else 'minimal'}")
        print()


if __name__ == "__main__":
    # Run the demonstration
    results = demonstrate_semantic_scoring()
    show_vector_analysis()
    
    print("\nüîß OPTIMIZATION SUGGESTIONS:")
    print("-" * 60)
    print("1. Use hybrid search (keyword + semantic) for balanced results")
    print("2. Boost keyword matching for single-word brand queries")
    print("3. Use semantic search strength for multi-word contextual queries")
    print("4. Consider query expansion for ambiguous short queries")
    print("\nYour search service already supports these optimizations! üéØ")