# End-to-End Testing Quick Reference

## ğŸš€ Quick Start Commands

```bash
# Run example test
python examples/test_example.py

# Test accuracy with ground truth
python tests/test_accuracy_framework.py tests/ground_truth_template.json

# Benchmark performance
python tests/test_performance_benchmark.py documents/input/ --operations end_to_end

# Install additional dependencies
pip install psutil
```

## ğŸ“Š Key Metrics Measured

### OCR Accuracy
- **Keyword Detection**: % of expected terms found
- **Confidence Score**: OCR engine confidence (0-1)
- **Success Rate**: % files processed without errors

### Extraction Accuracy  
- **Parse Success**: % documents successfully extracted
- **Metadata Completeness**: File info availability
- **Text Quality**: Content length and coherence

### Classification Accuracy
- **Overall Accuracy**: % correctly classified documents
- **Per-Category**: Performance by document type
- **Confidence Distribution**: Reliability of predictions

### Performance Metrics
- **Throughput**: Files/second, MB/second
- **Latency**: Average/median processing time
- **Resources**: Peak memory, CPU usage

## ğŸ¯ Accuracy Thresholds

| Metric | Good | Excellent |
|--------|------|-----------|
| Overall Pipeline | â‰¥85% | â‰¥95% |
| OCR (clear text) | â‰¥95% | â‰¥99% |
| OCR (scanned) | â‰¥80% | â‰¥90% |
| Classification | â‰¥90% | â‰¥95% |
| Extraction | â‰¥98% | â‰¥99.5% |

## âš¡ Performance Benchmarks

| Operation | Typical Range | Good Performance |
|-----------|---------------|------------------|
| PDF Extraction | 5-50 MB/s | >20 MB/s |
| OCR Processing | 0.5-5 MB/s | >2 MB/s |
| Classification | 10-100 docs/s | >50 docs/s |
| End-to-End | 5-30 docs/s | >15 docs/s |

## ğŸ”§ Architecture Boundaries Tested

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input File    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€â”€ OCR Layer Testing
â”‚   OCR Service   â”‚      â€¢ Text extraction accuracy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â€¢ Confidence scores
         â”‚               â€¢ Processing speed
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€â”€ Extraction Layer Testing  
â”‚ Document        â”‚      â€¢ Content parsing
â”‚ Extraction      â”‚      â€¢ Metadata extraction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â€¢ Format support
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€â”€ Classification Layer Testing
â”‚ AI              â”‚      â€¢ Category prediction
â”‚ Classification  â”‚      â€¢ Confidence levels
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â€¢ Reasoning quality
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€â”€ End-to-End Testing
â”‚ Final Result    â”‚      â€¢ Overall accuracy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â€¢ Complete pipeline performance
```

## ğŸ“ File Structure

```
tests/
â”œâ”€â”€ test_accuracy_framework.py      # Accuracy testing framework
â”œâ”€â”€ test_performance_benchmark.py   # Performance benchmarking  
â”œâ”€â”€ ground_truth_template.json      # Sample ground truth data
â””â”€â”€ sample_ground_truth.json        # Auto-generated test data

examples/
â””â”€â”€ test_example.py                 # Quick start example

results/
â”œâ”€â”€ accuracy/                       # Accuracy test results
â”‚   â”œâ”€â”€ detailed_results_*.csv
â”‚   â””â”€â”€ summary_report_*.json
â””â”€â”€ performance/                    # Performance test results
    â””â”€â”€ benchmark_results_*.json
```

## ğŸ› ï¸ Common Commands

```bash
# Test single document accuracy
python -c "
import asyncio
from tests.test_accuracy_framework import AccuracyTestFramework
from pathlib import Path

async def test():
    framework = AccuracyTestFramework()
    await framework.initialize()
    result = await framework.test_classification_accuracy(
        Path('document.pdf'), 'invoice'
    )
    print(f'Accuracy: {result.correct_prediction}')

asyncio.run(test())
"

# Monitor resource usage
python -c "
import psutil, time
process = psutil.Process()
for i in range(5):
    print(f'Memory: {process.memory_info().rss/1024/1024:.1f}MB')
    time.sleep(1)
"

# Quick performance check
time python examples/test_example.py
```

## ğŸš¨ Troubleshooting

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError: psutil` | `pip install psutil` |
| No test files found | Add documents to `documents/input/` |
| OCR accuracy low | Check image quality, try different formats |
| Classification errors | Review categories, check model responses |
| Memory usage high | Reduce batch size, check for leaks |
| Slow performance | Monitor CPU/disk, optimize async operations |

## ğŸ“ˆ Monitoring & CI/CD

```yaml
# GitHub Actions example
name: Quality Tests
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Test Accuracy
        run: python tests/test_accuracy_framework.py tests/ci_ground_truth.json
      - name: Benchmark Performance  
        run: python tests/test_performance_benchmark.py documents/regression/
```

## ğŸ“š Next Steps

1. **Add Test Data**: Place documents in `documents/input/`
2. **Create Ground Truth**: Update `tests/ground_truth_template.json`
3. **Run Tests**: Use commands above to validate accuracy
4. **Monitor Performance**: Set up regular benchmarking
5. **Automate**: Add to CI/CD pipeline for continuous validation

---

## See Also

### Testing Documentation
- **[END_TO_END_TESTING_GUIDE.md](END_TO_END_TESTING_GUIDE.md)** - Complete testing guide with detailed instructions
- **[TESTING_GUIDE.md](TESTING_GUIDE.md)** - Testing strategy and organization

### Architecture Documentation
- **[SOLID_ARCHITECTURE.md](SOLID_ARCHITECTURE.md)** - Protocol-based design enables easy testing
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture and component overview

### Related Guides
- **[README.md](README.md)** - Main project documentation
- **[OCR_IMPLEMENTATION.md](OCR_IMPLEMENTATION.md)** - OCR implementation details

---

**Last Updated:** October 2025